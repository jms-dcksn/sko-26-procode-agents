{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f3627dc",
   "metadata": {},
   "source": [
    "# Bonus Time\n",
    "\n",
    "We'll start with the agent we built in ex 1, but add a UiPath-hosted MCP server, so the agent can invoke a MCP tool.\n",
    "\n",
    "There is an MCP Server created in AMER Presales folder in staging.uipath.com/uipathlabs - the URL for this srever is: https://staging.uipath.com/uipathlabs/Playground/agenthub_/mcp/4332993a-91e0-4b3c-84ca-c4b47bf6e386/uipath-genai-websummary\n",
    "\n",
    "The MCP server contains one tool - the GenAI Activities Web Summary activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09728aee",
   "metadata": {},
   "source": [
    "## First things first\n",
    "\n",
    "Let's run some imports for libraries and set up our LLM to go through the UiPath trust layer again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b80fec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response content: {\"id\":\"chatcmpl-Cz83MjkpfOfTr8AbJYdv1Wz5OGYqu\",\"model\":\"gpt-4o-2024-11-20\",\"object\":\"chat.completion\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"content\":\"The Moon does not have a capital, as it is not a country or governed by any political entity. It is a natural satellite of Earth. However, humans have explored the Moon, and notable locations include the Apollo landing sites, such as Tranquility Base, where Apollo 11 landed in 1969.\",\"role\":\"assistant\"}}],\"created\":1768685000,\"usage\":{\"completion_tokens\":64,\"prompt_tokens\":15,\"total_tokens\":79,\"cache_read_input_tokens\":0}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The Moon does not have a capital, as it is not a country or governed by any political entity. It is a natural satellite of Earth. However, humans have explored the Moon, and notable locations include the Apollo landing sites, such as Tranquility Base, where Apollo 11 landed in 1969.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 15, 'total_tokens': 79, 'cache_read_input_tokens': 0}, 'model_name': 'gpt-4o-2024-11-20', 'finish_reason': 'stop', 'system_fingerprint': 'chatcmpl-Cz83MjkpfOfTr8AbJYdv1Wz5OGYqu', 'created': 1768685000}, id='lc_run--019bcdd7-561c-7281-bbce-b80dfd0337a4-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 64, 'total_tokens': 79})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain.agents import create_agent\n",
    "from uipath_langchain.chat.models import UiPathChat\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from mcp import ClientSession\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "llm = UiPathChat(\n",
    "    model=\"gpt-4o-2024-11-20\",\n",
    "    temperature=0,\n",
    "    max_tokens=4000,\n",
    "    timeout=30,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "llm.invoke(\"What is the capital of the moon?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf53bb6",
   "metadata": {},
   "source": [
    "# Now we'll get right to business\n",
    "\n",
    "We'll define a simple agent like before, but this time wrap the agent with an MCP client. \n",
    "\n",
    "This follows a simple sequence:\n",
    "\n",
    "* Connect to MCP server\n",
    "* Read the available tools\n",
    "* Add those tools to the agent\n",
    "* Invoke the agent\n",
    "\n",
    "MCP allows us to decouple the tools definition from the agent or worflow code that runs the agent - this means that I can change the tools on the server without changing the code we're writing here. This separation speeds up development, since teams can independently build tool catalogs, while agent engineers can simply discover and add them to agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fed10",
   "metadata": {},
   "source": [
    "### Connect to the MCP Server with a client\n",
    "\n",
    "The below code creates the connection so the client can discover which tools are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f5a16f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='webSummary', description='Generate AI-based summaries of web search results, synthesizing insights from multiple sources with citations.', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'title': 'Search', 'description': 'The natural language query to search the web for'}}, 'additionalProperties': False, 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7d2be5074ae0>)]\n"
     ]
    }
   ],
   "source": [
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            \"transport\": \"http\",\n",
    "            \"url\": \"https://staging.uipath.com/uipathlabs/Playground/agenthub_/mcp/4332993a-91e0-4b3c-84ca-c4b47bf6e386/uipath-genai-websummary\",\n",
    "            \"headers\": {  \n",
    "                \"Authorization\": \"Bearer \" + os.getenv(\"UIPATH_ACCESS_TOKEN\"),  \n",
    "            },  \n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools()\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a00d3",
   "metadata": {},
   "source": [
    "### Create the agent with the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eae5a06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some recent developments in AI agents:\n",
      "\n",
      "1. **LiveRamp's Agentic Orchestration Launch** (October 2025): LiveRamp introduced a platform enabling autonomous AI agents to access identity resolution and audience activation tools, supporting marketing operations. This comes amid a significant rise in agentic AI job postings.\n",
      "\n",
      "2. **G2's AI Roundup**: Highlights include OpenAI's partnership with Bain & Company for B2B applications, ChatGPT's Search rollout for real-time information retrieval, and advancements in MarTech like Zeta Global's acquisition of LiveIntent for identity resolution.\n",
      "\n",
      "3. **Microsoft's Copilot Studio**: Microsoft announced the public preview of Copilot Studio, which allows users to create autonomous agents. This initiative is scaling into 2025.\n",
      "\n",
      "4. **C.H. Robinson's AI Agent Fleet Expansion**: The company expanded its fleet of AI agents, automating over 3 million tasks such as quoting and order processing.\n",
      "\n",
      "5. **Enterprise Adoption Trends**: By 2025, 45% of enterprises are expected to run production AI agents accessing critical systems, marking a 300% increase from 2023. Security concerns like prompt injection and model poisoning are driving the need for real-time monitoring and frameworks like NIST AI RMF.\n",
      "\n",
      "6. **AI Shopping Agents**: ChatGPT and Google have rolled out AI agents for research, comparison, and purchases. About 25% of young U.S. consumers are using AI for shopping, prompting retailers to optimize for generative engine optimization (GEO).\n",
      "\n",
      "These updates reflect rapid advancements in agentic AI systems for automation, marketing, and supply chains. For more details, you can explore sources like [G2's AI roundup](https://learn.g2.com/tech-signals-october-news-round-up) and [Microsoft's blog](https://blogs.microsoft.com/blog/2024/10/21/new-autonomous-agents-scale-your-team-like-never-before/).\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "agent = create_agent(llm, tools=tools)\n",
    "\n",
    "### Invoke the agent\n",
    "\n",
    "result = await agent.ainvoke({\"messages\": [HumanMessage(content=\"Tell me the latest in AI Agent news\")]})\n",
    "print(result[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866f1a1",
   "metadata": {},
   "source": [
    "# Your challenge\n",
    "\n",
    "Take this agent and add structured input/output with the graph approach that we used in the main exercise."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
